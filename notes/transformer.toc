\contentsline {section}{\numberline {1}Introduction to Logistic Regression}{2}{section.1}%
\contentsline {subsection}{\numberline {1.1}The Sigmoid Function}{2}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Loss and Cost Functions}{2}{subsection.1.2}%
\contentsline {subsubsection}{\numberline {1.2.1}Example Calculation of Loss}{2}{subsubsection.1.2.1}%
\contentsline {subsection}{\numberline {1.3}Optimization Using Gradient Descent}{3}{subsection.1.3}%
\contentsline {subsubsection}{\numberline {1.3.1}Numerical Example of Gradient Descent}{3}{subsubsection.1.3.1}%
\contentsline {subsection}{\numberline {1.4}Learning Rate}{4}{subsection.1.4}%
\contentsline {section}{\numberline {2}Artificial Neural Networks (ANN)}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Structure of a Neural Network}{5}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Activation Functions}{5}{subsection.2.2}%
\contentsline {section}{\numberline {3}Building a 2-Layer Neural Network}{6}{section.3}%
\contentsline {subsection}{\numberline {3.1}Size of Layers and Initializing Parameters}{6}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Parameter Initialization Strategy}{6}{subsubsection.3.1.1}%
\contentsline {subsection}{\numberline {3.2}Forward Propagation}{6}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Loss and Cost Functions}{6}{subsection.3.3}%
\contentsline {subsection}{\numberline {3.4}Backward Propagation}{7}{subsection.3.4}%
\contentsline {subsection}{\numberline {3.5}Parameter Update}{7}{subsection.3.5}%
\contentsline {subsection}{\numberline {3.6}Prediction with Trained Parameters}{7}{subsection.3.6}%
\contentsline {section}{\numberline {4}Conclusion}{7}{section.4}%
